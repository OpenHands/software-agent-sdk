---
name: Run Eval

on:
    pull_request_target:
        types: [labeled]
    release:
        types: [published]
    workflow_dispatch:
        inputs:
            sdk_ref:
                description: SDK commit/ref to evaluate
                required: true
                default: main
            eval_limit:
                description: Number of SWE-bench instances to run
                required: true
                default: '1'
                type: choice
                options:
                    - '1'
                    - '2'
                    - '10'
                    - '50'
                    - '100'
            model_stubs:
                description: Comma-separated model stubs to evaluate (must be allowlisted)
                required: false
                default: ''
                type: string
            reason:
                description: Reason for manual trigger
                required: false
                default: ''

env:
    BENCHMARKS_REPO: OpenHands/benchmarks
    BENCHMARKS_REF: openhands/workflow-call-support
    EVAL_REPO: OpenHands/evaluation
    EVAL_REF: openhands/workflow-call-support
    DATASET: princeton-nlp/SWE-bench_Verified
    SPLIT: test
    MAX_BUILD_WORKERS: '32'
    EVAL_AGENT_IMAGE: ghcr.io/openhands/eval-agent-server
    EVAL_AGENT_TARGET: source-minimal

jobs:
    prepare:
        if: >
            github.event_name == 'release' ||
            github.event_name == 'workflow_dispatch' ||
            (github.event_name == 'pull_request_target' &&
             (github.event.label.name == 'run-eval-1' ||
              github.event.label.name == 'run-eval-2' ||
              github.event.label.name == 'run-eval-50' ||
              github.event.label.name == 'run-eval-100'))
        runs-on: ubuntu-latest
        permissions:
            contents: read
            issues: write
            pull-requests: write
        outputs:
            eval_limit: ${{ steps.params.outputs.eval_limit }}
            sdk_ref: ${{ steps.params.outputs.sdk_ref }}
            sdk_sha: ${{ steps.get-sha.outputs.sdk_sha }}
            models: ${{ steps.params.outputs.models }}
            pr_number: ${{ steps.params.outputs.pr_number }}
            trigger_desc: ${{ steps.params.outputs.trigger_desc }}

        steps:
            - name: Checkout sdk code (base for validation)
              uses: actions/checkout@v4
              with:
                  ref: ${{ github.event_name == 'pull_request_target' && github.event.pull_request.base.sha || github.ref }}
                  fetch-depth: 0

            - name: Load allowlists
              id: allowlists
              run: |
                  ALLOWED_MODELS_JSON=$(jq -c '.' .github/run-eval/allowed-model-stubs.json)
                  DEFAULT_MODEL=$(echo "$ALLOWED_MODELS_JSON" | jq -r '.[0]')
                  if [ -z "$DEFAULT_MODEL" ]; then
                    echo "No default model stub configured" >&2
                    exit 1
                  fi
                  echo "allowed_models=$ALLOWED_MODELS_JSON" >> "$GITHUB_OUTPUT"
                  echo "default_model=$DEFAULT_MODEL" >> "$GITHUB_OUTPUT"

            - name: Validate labeler
              if: github.event_name == 'pull_request_target'
              run: |
                  LABELER="${{ github.actor }}"
                  if ! grep -Fx "$LABELER" .github/run-eval/authorized-labelers.txt >/dev/null; then
                    echo "User $LABELER is not authorized to trigger eval." >&2
                    exit 1
                  fi

            - name: Resolve parameters
              id: params
              env:
                  DEFAULT_MODEL: ${{ steps.allowlists.outputs.default_model }}
                  ALLOWED_MODELS_JSON: ${{ steps.allowlists.outputs.allowed_models }}
              run: |
                  set -euo pipefail

                  # Determine eval limit based on trigger
                  if [ "${{ github.event_name }}" = "pull_request_target" ]; then
                    LABEL="${{ github.event.label.name }}"
                    case "$LABEL" in
                      run-eval-1) EVAL_LIMIT=1 ;;
                      run-eval-2) EVAL_LIMIT=2 ;;
                      run-eval-50) EVAL_LIMIT=50 ;;
                      run-eval-100) EVAL_LIMIT=100 ;;
                      *) echo "Unsupported label $LABEL" >&2; exit 1 ;;
                    esac
                    SDK_REF="${{ github.event.pull_request.head.ref }}"
                    PR_NUMBER="${{ github.event.pull_request.number }}"
                    TRIGGER_DESCRIPTION="Label '${LABEL}' on PR #${PR_NUMBER}"
                  elif [ "${{ github.event_name }}" = "release" ]; then
                    EVAL_LIMIT=50
                    SDK_REF="${{ github.event.release.tag_name }}"
                    PR_NUMBER=""
                    TRIGGER_DESCRIPTION="Release ${{ github.event.release.tag_name }}"
                  else
                    EVAL_LIMIT="${{ github.event.inputs.eval_limit }}"
                    SDK_REF="${{ github.event.inputs.sdk_ref }}"
                    PR_NUMBER=""
                    REASON="${{ github.event.inputs.reason }}"
                    if [ -z "$REASON" ]; then
                      REASON="manual"
                    fi
                    TRIGGER_DESCRIPTION="Manual trigger: ${REASON}"
                  fi

                  # Normalize and validate models
                  MODELS_INPUT="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.model_stubs || '' }}"
                  if [ -z "$MODELS_INPUT" ]; then
                    MODELS_INPUT="$DEFAULT_MODEL"
                  fi
                  MODELS=$(printf '%s' "$MODELS_INPUT" | tr ', ' '\n' | sed '/^$/d' | paste -sd, -)
                  ALLOWED_LIST=$(echo "$ALLOWED_MODELS_JSON" | jq -r '.[]')
                  for MODEL in ${MODELS//,/ }; do
                    if ! echo "$ALLOWED_LIST" | grep -Fx "$MODEL" >/dev/null; then
                      echo "Model stub '$MODEL' is not allowlisted" >&2
                      exit 1
                    fi
                  done

                  echo "eval_limit=$EVAL_LIMIT" >> "$GITHUB_OUTPUT"
                  echo "sdk_ref=$SDK_REF" >> "$GITHUB_OUTPUT"
                  echo "models=$MODELS" >> "$GITHUB_OUTPUT"
                  echo "pr_number=$PR_NUMBER" >> "$GITHUB_OUTPUT"
                  echo "trigger_desc=$TRIGGER_DESCRIPTION" >> "$GITHUB_OUTPUT"

            - name: Checkout evaluated ref for PRs
              if: github.event_name == 'pull_request_target'
              run: |
                  set -euo pipefail
                  # Switch to the PR head for image build and SDK pinning.
                  REF="${{ steps.params.outputs.sdk_ref }}"
                  git fetch origin "$REF" --force
                  git checkout FETCH_HEAD

            - name: Get current commit SHA
              id: get-sha
              run: |
                  SDK_SHA=$(git rev-parse HEAD)
                  echo "sdk_sha=$SDK_SHA" >> "$GITHUB_OUTPUT"
                  echo "Using SDK commit: $SDK_SHA"

    build-benchmarks:
        needs: prepare
        uses: OpenHands/benchmarks/.github/workflows/build-swe-bench-images.yml@openhands/workflow-call-support
        with:
            dataset: princeton-nlp/SWE-bench_Verified
            split: test
            max-workers: '32'
            n-limit: ${{ needs.prepare.outputs.eval_limit }}
            sdk-commit: ${{ needs.prepare.outputs.sdk_sha }}

    dispatch-evaluation:
        needs: [prepare, build-benchmarks]
        runs-on: ubuntu-latest
        permissions:
            contents: read
        steps:
            - name: Dispatch evaluation workflow
              env:
                  SDK_SHA: ${{ needs.prepare.outputs.sdk_sha }}
                  EVAL_LIMIT: ${{ needs.prepare.outputs.eval_limit }}
                  MODELS: ${{ needs.prepare.outputs.models }}
                  EVAL_REPO: ${{ env.EVAL_REPO }}
              run: |
                  echo "Dispatching evaluation workflow with SDK commit: $SDK_SHA"
                  PAYLOAD=$(jq -n \
                    --arg sdk "$SDK_SHA" \
                    --arg eval_limit "$EVAL_LIMIT" \
                    --arg models "$MODELS" \
                    '{ref: "${{ env.EVAL_REF }}", inputs: {sdk_commit: $sdk, eval_limit: $eval_limit, models: $models}}')
                  RESPONSE=$(curl -sS -o /tmp/dispatch.out -w "%{http_code}" -X POST \
                    -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
                    -H "Accept: application/vnd.github+json" \
                    -d "$PAYLOAD" \
                    "https://api.github.com/repos/${EVAL_REPO}/actions/workflows/eval-job.yml/dispatches")
                  if [ "$RESPONSE" != "204" ]; then
                    echo "Dispatch failed (status $RESPONSE):" >&2
                    cat /tmp/dispatch.out >&2
                    exit 1
                  fi
                  echo "Evaluation workflow dispatched successfully (async - no polling)"

    comment-on-pr:
        needs: [prepare, build-benchmarks, dispatch-evaluation]
        if: always()
        runs-on: ubuntu-latest
        permissions:
            contents: read
            issues: write
            pull-requests: write
        steps:
            - name: Checkout for PR lookup
              uses: actions/checkout@v4

            - name: Comment on PR
              env:
                  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
                  SDK_SHA: ${{ needs.prepare.outputs.sdk_sha }}
                  EVAL_LIMIT: ${{ needs.prepare.outputs.eval_limit }}
                  MODELS: ${{ needs.prepare.outputs.models }}
                  TRIGGER_DESC: ${{ needs.prepare.outputs.trigger_desc }}
                  EVENT_NAME: ${{ github.event_name }}
                  PR_NUMBER_INPUT: ${{ needs.prepare.outputs.pr_number }}
                  IMAGES_BUILT: ${{ needs.build-benchmarks.outputs.images_built }}
                  BUILD_STATUS: ${{ needs.build-benchmarks.result }}
                  EVAL_STATUS: ${{ needs.dispatch-evaluation.result }}
              run: |
                  set -euo pipefail
                  PR_NUMBER="$PR_NUMBER_INPUT"
                  if [ "$EVENT_NAME" = "release" ] && [ -z "$PR_NUMBER" ]; then
                    # Attempt to find the merged PR for this commit
                    PR_NUMBER=$(curl -sS \
                      -H "Authorization: Bearer $GITHUB_TOKEN" \
                      -H "Accept: application/vnd.github+json" \
                      "https://api.github.com/repos/${{ github.repository }}/commits/${SDK_SHA}/pulls" \
                      | jq -r '.[0].number // ""')
                  fi

                  if [ -z "$PR_NUMBER" ]; then
                    echo "No PR found to comment on; skipping comment"
                    exit 0
                  fi

                  # Build status message
                  if [ "$BUILD_STATUS" = "success" ]; then
                    BUILD_MSG="✅ Built $IMAGES_BUILT images"
                  else
                    BUILD_MSG="❌ Build failed"
                  fi

                  if [ "$EVAL_STATUS" = "success" ]; then
                    EVAL_MSG="✅ Evaluation started"
                  elif [ "$EVAL_STATUS" = "skipped" ]; then
                    EVAL_MSG="⏭️ Evaluation skipped (build failed)"
                  else
                    EVAL_MSG="❌ Evaluation failed"
                  fi

                  COMMENT_BODY=$(cat <<EOF
                  **Evaluation Triggered**

                  - Trigger: $TRIGGER_DESC
                  - SDK: \`$SDK_SHA\`
                  - Eval limit: $EVAL_LIMIT
                  - Models: $MODELS

                  **Status:**
                  - Benchmarks: $BUILD_MSG
                  - Evaluation: $EVAL_MSG

                  [View workflow run](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
                  EOF
                  )

                  curl -sS -X POST \
                    -H "Accept: application/vnd.github+json" \
                    -H "Authorization: Bearer $GITHUB_TOKEN" \
                    "https://api.github.com/repos/${{ github.repository }}/issues/${PR_NUMBER}/comments" \
                    -d "$(jq -n --arg body "$COMMENT_BODY" '{body: $body}')"
